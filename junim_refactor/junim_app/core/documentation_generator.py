"""
Gerador de documenta√ß√£o t√©cnica para projetos Delphi
Focado exclusivamente em prompts espec√≠ficos - SEM FALLBACKS
"""

import os
import json
import re
import logging
from typing import Dict, Any, List, Optional
from pathlib import Path
from datetime import datetime

logger = logging.getLogger(__name__)

class DocumentationGenerator:
    """Gerador de documenta√ß√£o t√©cnica - APENAS com prompts e dados espec√≠ficos"""
    
    def __init__(self, llm_service=None, prompt_manager=None):
        self.llm_service = llm_service
        self.prompt_manager = prompt_manager
        self.docs_dir = Path("generated_docs")
        self.docs_dir.mkdir(exist_ok=True)
        
        # Apenas os 4 documentos essenciais solicitados
        self.document_types = {
            'project_functions': {
                'name': '‚öôÔ∏è Fun√ß√µes do Projeto Original',
                'prompt_type': 'project_functions',
                'filename': 'project_functions.md'
            },
            'project_diagram': {
                'name': 'üìä Diagrama do Projeto Original',
                'prompt_type': 'project_diagram',
                'filename': 'project_diagram.md'
            },
            'delphi_java_correlation': {
                'name': 'üîó Correla√ß√£o Delphi-Java',
                'prompt_type': 'correlations',
                'filename': 'delphi_java_correlation.md'
            },
            'project_description': {
                'name': 'üìù Descri√ß√£o do Projeto',
                'prompt_type': 'project_description',
                'filename': 'project_description.md'
            }
        }

    def generate_specific_documentation(self, analysis_results: Dict[str, Any], 
                                      project_name: str = "Projeto",
                                      include_mermaid: bool = True,
                                      documents_to_generate: List[str] = None) -> Dict[str, str]:
        """
        Gera APENAS documenta√ß√£o espec√≠fica usando prompts - SEM FALLBACKS
        
        Returns:
            Dict com conte√∫do dos documentos gerados (n√£o caminhos)
        """
        try:
            logger.info(f"üöÄ Gerando documenta√ß√£o essencial para: {project_name}")
            
            # Valida√ß√£o cr√≠tica dos dados de entrada
            if not analysis_results or not isinstance(analysis_results, dict):
                error_msg = f"‚ùå ERRO CR√çTICO: Dados de an√°lise inv√°lidos para {project_name}"
                logger.error(error_msg)
                raise ValueError(error_msg)
            
            logger.info(f"üìã Dados dispon√≠veis: {list(analysis_results.keys())}")
            
            # Cria diret√≥rio espec√≠fico para o projeto
            project_dir = self.docs_dir / self._sanitize_filename(project_name)
            project_dir.mkdir(exist_ok=True)
            
            generated_docs = {}
            
            # LISTA FIXA DOS 4 DOCUMENTOS ESSENCIAIS
            if documents_to_generate is None:
                documents_to_generate = [
                    'project_functions',
                    'project_diagram', 
                    'delphi_java_correlation',
                    'project_description'
                ]
            
            # Gera apenas documentos especificados - SEM FALLBACKS
            for doc_type in documents_to_generate:
                if doc_type in self.document_types:
                    doc_info = self.document_types[doc_type]
                    logger.info(f"üìÑ Gerando documento: {doc_info['name']}")
                    
                    # Gera o documento usando prompts reais
                    content = self._generate_document_content(doc_type, analysis_results, project_name)
                    
                    if not content or len(content.strip()) < 100:
                        error_msg = f"‚ùå FALHA na gera√ß√£o de {doc_info['name']} - Conte√∫do insuficiente"
                        logger.error(error_msg)
                        raise RuntimeError(error_msg)
                    
                    # Salva o documento
                    doc_path = project_dir / doc_info['filename']
                    with open(doc_path, 'w', encoding='utf-8') as f:
                        f.write(content)
                    
                    # Retorna o conte√∫do (n√£o o caminho)
                    generated_docs[doc_type] = content
                    logger.info(f"‚úÖ Documento gerado: {doc_info['name']} ({len(content)} chars)")
            
            # Gera README espec√≠fico
            readme_content = self._generate_essential_readme(analysis_results, project_name, list(generated_docs.keys()))
            readme_path = project_dir / "README.md"
            with open(readme_path, 'w', encoding='utf-8') as f:
                f.write(readme_content)
            generated_docs['readme'] = readme_content
            
            logger.info(f"üéâ Documenta√ß√£o essencial gerada: {len(generated_docs)} arquivos")
            logger.info(f"üìÅ Documentos salvos em: {project_dir}")
            return generated_docs
            
        except Exception as e:
            error_msg = f"‚ùå ERRO CR√çTICO na gera√ß√£o de documenta√ß√£o: {str(e)}"
            logger.error(error_msg)
            raise RuntimeError(error_msg) from e

    def _generate_document_content(self, doc_type: str, analysis_results: Dict[str, Any], 
                                   project_name: str) -> str:
        """
        Gera conte√∫do de um documento espec√≠fico usando prompts - SEM FALLBACKS
        """
        try:
            # Valida√ß√£o do tipo de documento
            if doc_type not in self.document_types:
                raise ValueError(f"Tipo de documento '{doc_type}' n√£o suportado")
            
            doc_config = self.document_types[doc_type]
            
            # Obt√©m prompt espec√≠fico - OBRIGAT√ìRIO
            prompt = self._get_prompt_for_document(doc_config['prompt_type'])
            if not prompt or len(prompt) < 100:
                raise RuntimeError(f"Prompt inv√°lido para {doc_type}")
            
            # Prepara contexto - OBRIGAT√ìRIO
            context = self._prepare_context(analysis_results, project_name, doc_type)
            if not context or len(context) < 500:
                raise RuntimeError(f"Contexto insuficiente para {doc_type}")
            
            # Gera conte√∫do usando LLM - OBRIGAT√ìRIO
            content = self._generate_content_with_llm(prompt, context)
            if not content or len(content.strip()) < 100:
                raise RuntimeError(f"LLM falhou ao gerar conte√∫do para {doc_type}")
            
            return content
            
        except Exception as e:
            error_msg = f"Erro ao gerar {doc_type}: {str(e)}"
            logger.error(error_msg)
            raise RuntimeError(error_msg) from e

    def _get_prompt_for_document(self, prompt_type: str) -> str:
        """Obt√©m prompt espec√≠fico - FALHA se n√£o conseguir"""
        if not self.prompt_manager:
            raise RuntimeError("PromptManager n√£o dispon√≠vel - OBRIGAT√ìRIO para gera√ß√£o")
        
        try:
            # Mapeia tipos de prompt para m√©todos do PromptManager
            prompt_methods = {
                'project_functions': 'get_functionality_mapping_prompt',
                'project_diagram': 'get_backend_analysis_prompt',  # Usar backend para diagrama
                'correlations': 'get_backend_analysis_prompt',
                'project_description': 'get_backend_analysis_prompt'
            }
            
            method_name = prompt_methods.get(prompt_type)
            if not method_name or not hasattr(self.prompt_manager, method_name):
                raise RuntimeError(f"M√©todo {method_name} n√£o encontrado no PromptManager")
            
            method = getattr(self.prompt_manager, method_name)
            prompt = method()
            
            if not prompt or len(prompt) < 50:
                raise RuntimeError(f"Prompt vazio ou inv√°lido para {prompt_type}")
            
            logger.info(f"‚úÖ Prompt obtido para {prompt_type}: {len(prompt)} caracteres")
            return prompt
                
        except Exception as e:
            error_msg = f"Erro ao obter prompt para {prompt_type}: {str(e)}"
            logger.error(error_msg)
            raise RuntimeError(error_msg) from e

    def _prepare_context(self, analysis_results: Dict[str, Any], project_name: str, doc_key: str) -> str:
        """Prepara contexto espec√≠fico - FALHA se dados insuficientes"""
        
        # Valida√ß√£o rigorosa dos dados de entrada
        if not analysis_results or not isinstance(analysis_results, dict):
            raise ValueError("analysis_results est√° vazio ou inv√°lido")
        
        logger.info(f"üîç Preparando contexto para {doc_key}")
        logger.info(f"üìã Dados dispon√≠veis: {list(analysis_results.keys())}")
        
        # Formata dados de an√°lise
        formatted_data = self._format_analysis_data(analysis_results)
        if len(formatted_data) < 200:
            raise RuntimeError(f"Dados formatados insuficientes: {len(formatted_data)} chars")
        
        # Extrai especificidades do c√≥digo
        code_specifics = self._extract_code_specifics(analysis_results)
        if len(code_specifics) < 100:
            logger.warning(f"‚ö†Ô∏è Especifica√ß√µes do c√≥digo limitadas: {len(code_specifics)} chars")
        
        # Monta contexto completo
        context = f"""
===== CONTEXTO ESPEC√çFICO DO PROJETO =====
PROJETO: {project_name}
TIPO DE DOCUMENTO: {doc_key}

===== DADOS REAIS EXTRA√çDOS DA AN√ÅLISE =====
{formatted_data}

===== C√ìDIGO E COMPONENTES IDENTIFICADOS =====
{code_specifics}

===== INSTRU√á√ïES CR√çTICAS PARA IA =====
VOC√ä DEVE GERAR DOCUMENTA√á√ÉO T√âCNICA ESPEC√çFICA para este projeto Delphi ({project_name}).

üö® REGRAS OBRIGAT√ìRIAS:
1. Use EXCLUSIVAMENTE os dados fornecidos acima - n√£o invente nada
2. Mencione nomes ESPEC√çFICOS de classes, m√©todos e arquivos identificados
3. Foque em aspectos de backend e moderniza√ß√£o para Java Spring Boot
4. Use formata√ß√£o Markdown clara com t√≠tulos, subt√≠tulos e listas
5. Seja t√©cnico e preciso - EVITE descri√ß√µes gen√©ricas
6. Inclua exemplos pr√°ticos baseados APENAS no c√≥digo analisado

FORMATO ESPERADO: Documento Markdown t√©cnico espec√≠fico para {project_name}
N√ÉO USE INFORMA√á√ïES GEN√âRICAS - BASE-SE APENAS NOS DADOS FORNECIDOS ACIMA
        """
        
        logger.info(f"üéØ Contexto preparado: {len(context)} caracteres")
        
        if len(context) < 1000:
            raise RuntimeError(f"Contexto muito pequeno: {len(context)} caracteres")
        
        return context

    def _extract_code_specifics(self, analysis_results: Dict[str, Any]) -> str:
        """Extrai informa√ß√µes espec√≠ficas do c√≥digo"""
        try:
            specifics = []
            
            # Extrai classes identificadas
            all_classes = []
            files_data = analysis_results.get('files', {})
            
            if isinstance(files_data, dict):
                files_to_process = files_data.values()
            elif isinstance(files_data, list):
                files_to_process = files_data
            else:
                files_to_process = []
            
            for file_data in files_to_process:
                if isinstance(file_data, dict):
                    classes = file_data.get('classes', [])
                    for cls in classes:
                        class_name = cls.get('name', '')
                        parent_class = cls.get('parent_class', '')
                        if class_name:
                            all_classes.append(f"{class_name} (extends {parent_class})")
            
            if all_classes:
                specifics.append("**Classes Identificadas:**")
                for cls in all_classes[:10]:
                    specifics.append(f"- {cls}")
            
            # Extrai m√©todos importantes
            important_methods = []
            for file_data in files_to_process:
                if isinstance(file_data, dict):
                    methods = file_data.get('methods', [])
                    for method in methods:
                        method_name = method.get('name', '')
                        method_type = method.get('type', 'method')
                        return_type = method.get('return_type', 'void')
                        if method_name and not method_name.startswith('_'):
                            important_methods.append(f"{method_name}(): {return_type} ({method_type})")
            
            if important_methods:
                specifics.append("\n**M√©todos Principais:**")
                for method in important_methods[:15]:
                    specifics.append(f"- {method}")
            
            # Extrai eventos de interface
            event_methods = []
            for file_data in files_to_process:
                if isinstance(file_data, dict):
                    methods = file_data.get('methods', [])
                    for method in methods:
                        method_name = method.get('name', '')
                        if any(event in method_name for event in ['Click', 'Change', 'Create', 'Close', 'Show']):
                            event_methods.append(method_name)
            
            if event_methods:
                specifics.append("\n**Eventos de Interface:**")
                for event in event_methods[:10]:
                    specifics.append(f"- {event}")
            
            return "\n".join(specifics) if specifics else "Componentes b√°sicos identificados."
            
        except Exception as e:
            logger.error(f"Erro ao extrair especificidades: {str(e)}")
            return "Erro ao extrair detalhes do c√≥digo."

    def _format_analysis_data(self, analysis_results: Dict[str, Any]) -> str:
        """Formata dados de an√°lise de forma leg√≠vel"""
        try:
            formatted = []
            
            # Metadados do projeto
            metadata = analysis_results.get('metadata', {})
            formatted.append(f"**Projeto**: {metadata.get('project_name', 'N/A')}")
            formatted.append(f"**Arquivos Analisados**: {metadata.get('total_files_analyzed', 0)}")
            formatted.append(f"**Caminho**: {metadata.get('project_path', 'N/A')}")
            
            # Composi√ß√£o do projeto
            files_by_type = metadata.get('files_by_type', {})
            if files_by_type:
                formatted.append("\n**Composi√ß√£o do Projeto:**")
                for file_type, count in files_by_type.items():
                    if count > 0:
                        formatted.append(f"- Arquivos {file_type.upper()}: {count}")
            
            # Estat√≠sticas gerais
            summary = analysis_results.get('summary', {})
            if summary:
                formatted.append("\n**Estat√≠sticas Gerais:**")
                formatted.append(f"- Units: {summary.get('total_units', 0)}")
                formatted.append(f"- Forms: {summary.get('total_forms', 0)}")
                formatted.append(f"- Classes: {summary.get('total_classes', 0)}")
                formatted.append(f"- M√©todos: {summary.get('total_methods', 0)}")
            
            # Arquivos analisados
            files = analysis_results.get('files', {})
            if files:
                files_count = len(files) if isinstance(files, dict) else len(files) if isinstance(files, list) else 0
                formatted.append(f"\n**Arquivos Detalhados**: {files_count}")
                
                if isinstance(files, dict):
                    sample_files = list(files.keys())[:5]
                    for file_path in sample_files:
                        file_name = file_path.split('\\')[-1] if '\\' in file_path else file_path
                        formatted.append(f"- {file_name}")
            
            result = "\n".join(formatted)
            logger.info(f"‚úÖ Dados formatados: {len(result)} caracteres")
            
            return result if result else "Dados de an√°lise limitados"
            
        except Exception as e:
            logger.error(f"Erro ao formatar dados: {str(e)}")
            # Formato m√≠nimo em caso de erro
            return f"Projeto: {analysis_results.get('metadata', {}).get('project_name', 'N/A')}\nArquivos: {analysis_results.get('metadata', {}).get('total_files_analyzed', 0)}"

    def _generate_content_with_llm(self, prompt: str, context: str) -> str:
        """Gera conte√∫do usando LLM - FALHA se n√£o conseguir"""
        
        if not self.llm_service:
            raise RuntimeError("LLM service n√£o dispon√≠vel - OBRIGAT√ìRIO para gera√ß√£o")
        
        try:
            # Combina prompt especializado com contexto espec√≠fico
            full_prompt = f"{prompt}\n\n{context}"
            
            logger.info(f"üöÄ Gerando com LLM: {len(full_prompt)} caracteres")
            
            # Chama o LLM service
            content = self.llm_service.generate_response(full_prompt)
            
            if not content or len(content.strip()) < 100:
                raise RuntimeError("Resposta do LLM muito curta ou vazia")
            
            logger.info(f"‚úÖ Conte√∫do gerado: {len(content)} caracteres")
            return content
                
        except Exception as e:
            error_msg = f"Erro na gera√ß√£o com LLM: {str(e)}"
            logger.error(error_msg)
            raise RuntimeError(error_msg) from e

    def _generate_essential_readme(self, analysis_results: Dict[str, Any], 
                                 project_name: str, generated_docs_list: List[str]) -> str:
        """Gera README essencial para os 4 documentos principais"""
        
        metadata = analysis_results.get('metadata', {})
        total_files = metadata.get('total_files_analyzed', 0)
        total_lines = metadata.get('total_lines_analyzed', 0)
        
        readme = f"""# Documenta√ß√£o para Gera√ß√£o Java Spring Boot - {project_name}

## Resumo da An√°lise
- **Projeto**: {project_name}
- **Arquivos analisados**: {total_files}
- **Linhas de c√≥digo**: {total_lines:,}
- **Data da an√°lise**: {datetime.now().strftime('%d/%m/%Y %H:%M')}

## üìã Documentos Essenciais Gerados

### 1. ‚öôÔ∏è Fun√ß√µes do Projeto Original
**Arquivo**: `project_functions.md`
- Lista todas as fun√ß√µes identificadas no projeto Delphi
- M√©todos de Forms, Units e DataModules
- Base para gera√ß√£o dos m√©todos Java

### 2. üìä Diagrama do Projeto Original  
**Arquivo**: `project_diagram.md`
- Diagrama Mermaid da arquitetura atual
- Fluxo de dados identificado
- Estrutura visual para convers√£o

### 3. üîó Correla√ß√£o Delphi-Java
**Arquivo**: `delphi_java_correlation.md`
- Mapeamento direto de componentes Delphi ‚Üí Spring Boot
- Equival√™ncias de classes e m√©todos
- Padr√µes de convers√£o

### 4. üìù Descri√ß√£o do Projeto
**Arquivo**: `project_description.md`
- Vis√£o geral baseada na an√°lise
- Funcionalidades identificadas
- Caracter√≠sticas t√©cnicas

## üéØ Pr√≥ximos Passos
1. ‚úÖ An√°lise Delphi conclu√≠da
2. ‚úÖ Documenta√ß√£o essencial gerada
3. üîÑ **Pr√≥ximo**: Gera√ß√£o do c√≥digo Java Spring Boot
4. üîÑ Testes e valida√ß√£o

## üìä Estat√≠sticas da An√°lise
- **Units identificadas**: {len(analysis_results.get('units_analysis', {}))}
- **Forms identificados**: {len(analysis_results.get('forms_analysis', {}))}
- **Classes totais**: {analysis_results.get('summary', {}).get('total_classes', 0)}
- **M√©todos totais**: {analysis_results.get('summary', {}).get('total_methods', 0)}

---
*Documenta√ß√£o gerada automaticamente pelo Sistema JUNIM*
*Focada na gera√ß√£o de c√≥digo Java Spring Boot*
"""
        return readme

    def _sanitize_filename(self, filename: str) -> str:
        """Sanitiza nome do arquivo"""
        sanitized = re.sub(r'[<>:"/\\|?*]', '_', filename)
        sanitized = re.sub(r'\s+', '_', sanitized)
        return sanitized

    # M√©todos auxiliares para compatibilidade com interface existente
    def get_document_content(self, doc_key_or_path: str, project_name: str = "Projeto") -> str:
        """Obt√©m conte√∫do de um documento espec√≠fico"""
        try:
            if os.path.isfile(doc_key_or_path):
                with open(doc_key_or_path, 'r', encoding='utf-8') as f:
                    return f.read()
            
            doc_config = self.document_types.get(doc_key_or_path, {})
            filename = doc_config.get('filename', f'{doc_key_or_path}.md')
            
            project_dir = self.docs_dir / self._sanitize_filename(project_name)
            doc_path = project_dir / filename
            
            if doc_path.exists():
                with open(doc_path, 'r', encoding='utf-8') as f:
                    return f.read()
            else:
                return f"Documento n√£o encontrado: {doc_key_or_path}"
                
        except Exception as e:
            logger.error(f"Erro ao ler documento {doc_key_or_path}: {str(e)}")
            return f"Erro ao carregar documento: {str(e)}"
    
    def generate_complete_documentation(self, analysis_results: Dict[str, Any], 
                                      project_name: str = "Projeto") -> Dict[str, str]:
        """
        Gera documenta√ß√£o completa do projeto baseada na an√°lise
        
        Args:
            analysis_results: Resultados da an√°lise do projeto
            project_name: Nome do projeto
            
        Returns:
            Dict com caminhos dos documentos gerados
        """
        try:
            logger.info(f"üöÄ Iniciando gera√ß√£o de documenta√ß√£o completa para: {project_name}")
            
            # Cria diret√≥rio espec√≠fico para o projeto
            project_dir = self.docs_dir / self._sanitize_filename(project_name)
            project_dir.mkdir(exist_ok=True)
            
            generated_docs = {}
            
            # Gera cada tipo de documento
            for doc_key, doc_config in self.document_types.items():
                try:
                    logger.info(f"üìÑ Gerando documento: {doc_config['name']}")
                    
                    doc_path = self._generate_document(
                        doc_key=doc_key,
                        doc_config=doc_config,
                        analysis_results=analysis_results,
                        project_dir=project_dir,
                        project_name=project_name
                    )
                    
                    if doc_path:
                        generated_docs[doc_key] = str(doc_path)
                        logger.info(f"‚úÖ Documento gerado: {doc_config['name']}")
                    else:
                        logger.warning(f"‚ö†Ô∏è Falha ao gerar documento: {doc_config['name']}")
                        
                except Exception as e:
                    logger.error(f"‚ùå Erro ao gerar documento {doc_key}: {str(e)}")
                    continue
            
            # Salva metadados
            self._save_documentation_metadata(generated_docs, analysis_results, project_dir)
            
            logger.info(f"üéâ Documenta√ß√£o completa gerada: {len(generated_docs)} documentos")
            return generated_docs
            
        except Exception as e:
            logger.error(f"‚ùå Erro na gera√ß√£o de documenta√ß√£o: {str(e)}")
            return {}
    
    def _generate_document(self, doc_key: str, doc_config: Dict[str, Any], 
                          analysis_results: Dict[str, Any], project_dir: Path, 
                          project_name: str) -> Optional[Path]:
        """Gera um documento espec√≠fico"""
        try:
            # Obt√©m prompt espec√≠fico
            prompt = self._get_prompt_for_document(doc_config['prompt_type'])
            
            # Prepara contexto
            context = self._prepare_context(analysis_results, project_name, doc_key)
            
            # Gera conte√∫do usando LLM
            content = self._generate_content_with_llm(prompt, context)
            
            if not content or len(content.strip()) < 100:
                raise RuntimeError(f"Falha ao gerar conte√∫do para {doc_key}")
            
            # Salva documento
            doc_path = project_dir / doc_config['filename']
            with open(doc_path, 'w', encoding='utf-8') as f:
                f.write(content)
                
            return doc_path
            
        except Exception as e:
            logger.error(f"Erro ao gerar documento {doc_key}: {str(e)}")
            return None
    
    def _get_prompt_for_document(self, prompt_type: str) -> str:
        """Obt√©m prompt espec√≠fico para tipo de documento - FALHA se n√£o conseguir"""
        if not self.prompt_manager:
            raise RuntimeError("PromptManager n√£o dispon√≠vel - OBRIGAT√ìRIO para gera√ß√£o")
        
        try:
            # Mapeia tipos de prompt para m√©todos do PromptManager
            prompt_methods = {
                'project_functions': 'get_functionality_mapping_prompt',
                'project_diagram': 'get_backend_analysis_prompt',  # Usar backend para diagrama
                'correlations': 'get_backend_analysis_prompt',
                'project_description': 'get_backend_analysis_prompt'
            }
            
            method_name = prompt_methods.get(prompt_type)
            if not method_name or not hasattr(self.prompt_manager, method_name):
                raise RuntimeError(f"M√©todo {method_name} n√£o encontrado no PromptManager")
            
            method = getattr(self.prompt_manager, method_name)
            prompt = method()
            
            if not prompt or len(prompt) < 50:
                raise RuntimeError(f"Prompt vazio ou inv√°lido para {prompt_type}")
            
            logger.info(f"‚úÖ Prompt obtido para {prompt_type}: {len(prompt)} caracteres")
            return prompt
                
        except Exception as e:
            error_msg = f"Erro ao obter prompt para {prompt_type}: {str(e)}"
            logger.error(error_msg)
            raise RuntimeError(error_msg) from e
    
 
    def _prepare_context(self, analysis_results: Dict[str, Any], project_name: str, doc_key: str) -> str:
        """Prepara contexto para gera√ß√£o de documento - FALHA se dados insuficientes"""
        
        # Valida√ß√£o rigorosa dos dados de entrada
        if not analysis_results or not isinstance(analysis_results, dict):
            raise ValueError("analysis_results est√° vazio ou inv√°lido")
        
        logger.info(f"üîç Preparando contexto para {doc_key} - Dados dispon√≠veis: {list(analysis_results.keys())}")
        
        # Formata dados de forma mais leg√≠vel
        formatted_data = self._format_analysis_data(analysis_results)
        if len(formatted_data) < 200:
            raise RuntimeError(f"Dados formatados insuficientes: {len(formatted_data)} chars")
        
        # Adiciona informa√ß√µes espec√≠ficas do c√≥digo
        code_specifics = self._extract_code_specifics(analysis_results)
        if len(code_specifics) < 100:
            logger.warning(f"‚ö†Ô∏è Especifica√ß√µes do c√≥digo limitadas: {len(code_specifics)} chars")
        
        # Monta contexto completo - igual √† vers√£o limpa
        context = f"""
===== CONTEXTO ESPEC√çFICO DO PROJETO =====
PROJETO: {project_name}
TIPO DE DOCUMENTO: {doc_key}

===== DADOS REAIS EXTRA√çDOS DA AN√ÅLISE =====
{formatted_data}

===== C√ìDIGO E COMPONENTES IDENTIFICADOS =====
{code_specifics}

===== INSTRU√á√ïES CR√çTICAS PARA IA =====
VOC√ä DEVE GERAR DOCUMENTA√á√ÉO T√âCNICA ESPEC√çFICA para este projeto Delphi ({project_name}).

üö® REGRAS OBRIGAT√ìRIAS:
1. Use EXCLUSIVAMENTE os dados fornecidos acima - n√£o invente nada
2. Mencione nomes ESPEC√çFICOS de classes, m√©todos e arquivos identificados
3. Foque em aspectos de backend e moderniza√ß√£o para Java Spring Boot
4. Use formata√ß√£o Markdown clara com t√≠tulos, subt√≠tulos e listas
5. Seja t√©cnico e preciso - EVITE descri√ß√µes gen√©ricas
6. Inclua exemplos pr√°ticos baseados APENAS no c√≥digo analisado

FORMATO ESPERADO: Documento Markdown t√©cnico espec√≠fico para {project_name}
N√ÉO USE INFORMA√á√ïES GEN√âRICAS - BASE-SE APENAS NOS DADOS FORNECIDOS ACIMA
        """
        
        logger.info(f"üéØ Contexto preparado: {len(context)} caracteres")
        
        if len(context) < 1000:
            raise RuntimeError(f"Contexto muito pequeno: {len(context)} caracteres")
        
        return context
    
    def _extract_code_specifics(self, analysis_results: Dict[str, Any]) -> str:
        """Extrai informa√ß√µes espec√≠ficas do c√≥digo para enriquecer o contexto"""
        try:
            specifics = []
            
            # Extrai nomes de classes espec√≠ficas
            all_classes = []
            files_data = analysis_results.get('files', {})
            
            # Verifica se files √© um dicion√°rio ou lista
            if isinstance(files_data, dict):
                files_to_process = files_data.values()
            elif isinstance(files_data, list):
                files_to_process = files_data
            else:
                files_to_process = []
            
            for file_data in files_to_process:
                if isinstance(file_data, dict):
                    classes = file_data.get('classes', [])
                    for cls in classes:
                        class_name = cls.get('name', '')
                        parent_class = cls.get('parent_class', '')
                        if class_name:
                            all_classes.append(f"{class_name} (extends {parent_class})")
            
            if all_classes:
                specifics.append(f"**Classes Identificadas:**")
                for cls in all_classes[:10]:  # Limita para n√£o ficar muito longo
                    specifics.append(f"- {cls}")
            
            # Extrai m√©todos espec√≠ficos importantes
            important_methods = []
            files_data = analysis_results.get('files', {})
            
            # Verifica se files √© um dicion√°rio ou lista
            if isinstance(files_data, dict):
                files_to_process = files_data.values()
            elif isinstance(files_data, list):
                files_to_process = files_data
            else:
                files_to_process = []
                
            for file_data in files_to_process:
                if isinstance(file_data, dict):
                    methods = file_data.get('methods', [])
                    for method in methods:
                        method_name = method.get('name', '')
                        method_type = method.get('type', 'method')
                        return_type = method.get('return_type', 'void')
                        if method_name and not method_name.startswith('_'):  # Ignora m√©todos privados
                            important_methods.append(f"{method_name}(): {return_type} ({method_type})")
            
            if important_methods:
                specifics.append(f"\n**M√©todos Principais:**")
                for method in important_methods[:15]:  # Limita para n√£o ficar muito longo
                    specifics.append(f"- {method}")
            
            # Extrai padr√µes de nomenclatura
            naming_patterns = set()
            files_data = analysis_results.get('files', {})
            
            # Verifica se files √© um dicion√°rio ou lista
            if isinstance(files_data, dict):
                files_to_process = files_data.values()
            elif isinstance(files_data, list):
                files_to_process = files_data
            else:
                files_to_process = []
                
            for file_data in files_to_process:
                if isinstance(file_data, dict):
                    classes = file_data.get('classes', [])
                    for cls in classes:
                        class_name = cls.get('name', '')
                        if class_name.startswith('T'):
                            naming_patterns.add("Classes com prefixo T (padr√£o Delphi)")
                        if 'Form' in class_name:
                            naming_patterns.add("Classes de formul√°rio (UI)")
                        if 'DataModule' in class_name:
                            naming_patterns.add("DataModules (acesso a dados)")
            
            if naming_patterns:
                specifics.append(f"\n**Padr√µes Identificados:**")
                for pattern in naming_patterns:
                    specifics.append(f"- {pattern}")
            
            # Extrai informa√ß√µes sobre eventos (importante para UI)
            event_methods = []
            files_data = analysis_results.get('files', {})
            
            # Verifica se files √© um dicion√°rio ou lista
            if isinstance(files_data, dict):
                files_to_process = files_data.values()
            elif isinstance(files_data, list):
                files_to_process = files_data
            else:
                files_to_process = []
                
            for file_data in files_to_process:
                if isinstance(file_data, dict):
                    methods = file_data.get('methods', [])
                    for method in methods:
                        method_name = method.get('name', '')
                        if any(event in method_name for event in ['Click', 'Change', 'Create', 'Close', 'Show']):
                            event_methods.append(method_name)
            
            if event_methods:
                specifics.append(f"\n**Eventos de Interface:**")
                for event in event_methods[:10]:
                    specifics.append(f"- {event}")
            
            return "\n".join(specifics) if specifics else "Nenhum detalhe espec√≠fico adicional identificado."
            
        except Exception as e:
            logger.error(f"Erro ao extrair especificidades do c√≥digo: {str(e)}")
            return "Erro ao extrair detalhes espec√≠ficos do c√≥digo."
    
    def _format_analysis_data(self, analysis_results: Dict[str, Any]) -> str:
        """Formata dados de an√°lise de forma mais leg√≠vel e espec√≠fica"""
        try:
            formatted = []
            
            # CORRE√á√ÉO: Log para debug dos dados recebidos
            logger.info(f"üîç Formatando dados - Chaves dispon√≠veis: {list(analysis_results.keys())}")
            
            # Metadados do projeto
            metadata = analysis_results.get('metadata', {})
            formatted.append(f"**Projeto**: {metadata.get('project_name', 'N/A')}")
            formatted.append(f"**Data da An√°lise**: {metadata.get('analysis_date', 'N/A')}")
            formatted.append(f"**Arquivos Analisados**: {metadata.get('total_files_analyzed', 0)}")
            formatted.append(f"**Caminho**: {metadata.get('project_path', 'N/A')}")
            
            # Tipos de arquivos com detalhes
            files_by_type = metadata.get('files_by_type', {})
            if files_by_type:
                formatted.append("\n**Composi√ß√£o do Projeto:**")
                for file_type, count in files_by_type.items():
                    if count > 0:
                        formatted.append(f"- Arquivos {file_type.upper()}: {count}")
            
            # CORRE√á√ÉO: Extrair dados de todas as se√ß√µes poss√≠veis
            # Resumo detalhado do projeto
            summary = analysis_results.get('summary', {})
            if summary:
                formatted.append(f"\n**Estat√≠sticas Gerais:**")
                formatted.append(f"- Units: {summary.get('total_units', 0)}")
                formatted.append(f"- Forms: {summary.get('total_forms', 0)}")
                formatted.append(f"- DataModules: {summary.get('total_datamodules', 0)}")
                formatted.append(f"- Classes: {summary.get('total_classes', 0)}")
                formatted.append(f"- M√©todos: {summary.get('total_methods', 0)}")
            
            # CORRE√á√ÉO: Tentar extrair dados de m√∫ltiplas fontes
            # Dados dos arquivos analisados (nova se√ß√£o)
            files = analysis_results.get('files', {})
            if files:
                formatted.append(f"\n**Arquivos Analisados Detalhadamente:**")
                files_count = len(files) if isinstance(files, dict) else len(files) if isinstance(files, list) else 0
                formatted.append(f"- Total de arquivos detalhados: {files_count}")
                
                # Extrai amostras dos arquivos
                if isinstance(files, dict):
                    sample_files = list(files.keys())[:5]
                    for file_path in sample_files:
                        file_name = file_path.split('\\')[-1] if '\\' in file_path else file_path
                        formatted.append(f"- {file_name}")
            
            # M√©tricas de complexidade
            complexity = summary.get('complexity_metrics', {}) if summary else {}
            if complexity:
                formatted.append(f"\n**M√©tricas de Complexidade:**")
                formatted.append(f"- Complexidade M√©dia: {complexity.get('average_complexity', 0)}")
                formatted.append(f"- Complexidade M√°xima: {complexity.get('max_complexity', 0)}")
                formatted.append(f"- Total de Linhas: {complexity.get('total_lines', 0)}")
                formatted.append(f"- M√©todos Complexos: {complexity.get('methods_with_high_complexity', 0)}")
            
            # Funcionalidades principais espec√≠ficas
            functionalities = analysis_results.get('main_functionalities', [])
            if functionalities:
                formatted.append("\n**Funcionalidades Identificadas:**")
                for func in functionalities:
                    formatted.append(f"- {func}")
            
            # CORRE√á√ÉO: An√°lise detalhada de units com melhor tratamento de dados
            units_analysis = analysis_results.get('units_analysis', {})
            if units_analysis and isinstance(units_analysis, dict):
                formatted.append("\n**Componentes Principais (Units):**")
                units_list = list(units_analysis.items())[:10]  # Aumenta para 10 units
                for unit_path, unit_data in units_list:
                    if isinstance(unit_data, dict):
                        unit_name = unit_path.split('\\')[-1] if '\\' in unit_path else unit_path
                        unit_type = unit_data.get('unit_type', 'unit')
                        lines = unit_data.get('lines_count', 0)
                        methods = unit_data.get('methods', [])
                        classes = unit_data.get('classes', [])
                        
                        # Informa√ß√µes mais espec√≠ficas sobre cada unit
                        info_parts = [f"{lines} linhas", f"{len(methods)} m√©todos"]
                        if classes:
                            class_names = [cls.get('name', 'N/A') for cls in classes if isinstance(cls, dict)]
                            if class_names:
                                info_parts.append(f"classes: {', '.join(class_names)}")
                        
                        formatted.append(f"- **{unit_name}** ({unit_type}): {', '.join(info_parts)}")
                        
                        # Adiciona detalhes dos m√©todos mais importantes
                        if methods and isinstance(methods, list):
                            important_methods = [m for m in methods if isinstance(m, dict) and m.get('complexity', 0) > 1][:3]
                            if important_methods:
                                method_names = [m.get('name', 'N/A') for m in important_methods]
                                formatted.append(f"  ‚Üí M√©todos principais: {', '.join(method_names)}")
            
            # CORRE√á√ÉO: An√°lise detalhada de forms com melhor tratamento
            forms_analysis = analysis_results.get('forms_analysis', {})
            if forms_analysis and isinstance(forms_analysis, dict):
                formatted.append("\n**Interfaces (Forms):**")
                forms_list = list(forms_analysis.items())[:5]
                for form_path, form_data in forms_list:
                    if isinstance(form_data, dict):
                        form_name = form_path.split('\\')[-1] if '\\' in form_path else form_path
                        classes = form_data.get('classes', [])
                        methods = form_data.get('methods', [])
                        
                        class_info = ""
                        if classes and isinstance(classes, list) and len(classes) > 0:
                            main_class = classes[0].get('name', 'N/A') if isinstance(classes[0], dict) else 'N/A'
                            parent_class = classes[0].get('parent_class', 'N/A') if isinstance(classes[0], dict) else 'N/A'
                            class_info = f", classe: {main_class} ({parent_class})"
                        
                        lines_count = form_data.get('lines_count', 0)
                        method_count = len(methods) if isinstance(methods, list) else 0
                        formatted.append(f"- **{form_name}**: {lines_count} linhas, {method_count} m√©todos{class_info}")
                        
                        # Adiciona informa√ß√µes sobre eventos/handlers
                        if methods and isinstance(methods, list):
                            event_methods = [m for m in methods if isinstance(m, dict) and ('Click' in m.get('name', '') or 'Event' in m.get('name', ''))]
                            if event_methods:
                                event_names = [m.get('name', 'N/A') for m in event_methods[:3]]
                                formatted.append(f"  ‚Üí Eventos: {', '.join(event_names)}")
            
            # RESULTADO FINAL
            result = "\n".join(formatted)
            logger.info(f"‚úÖ Dados formatados: {len(result)} caracteres, {len(formatted)} se√ß√µes")
            
            return result if result else "Nenhum dado espec√≠fico foi extra√≠do da an√°lise."
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao formatar dados: {str(e)}")
            # Fallback para formato JSON mais limpo
            essential_data = {
                'project_name': analysis_results.get('metadata', {}).get('project_name', 'N/A'),
                'total_files': analysis_results.get('metadata', {}).get('total_files_analyzed', 0),
                'summary': analysis_results.get('summary', {}),
                'main_functionalities': analysis_results.get('main_functionalities', []),
                'units_count': len(analysis_results.get('units_analysis', {})),
                'forms_count': len(analysis_results.get('forms_analysis', {}))
            }
            return f"Dados da an√°lise (formato simplificado):\n{json.dumps(essential_data, indent=2, ensure_ascii=False)}"
    


    def _save_documentation_metadata(self, generated_docs: Dict[str, str], 
                                   analysis_results: Dict[str, Any], project_dir: Path):
        """Salva metadados da documenta√ß√£o"""
        try:
            metadata = {
                'generation_date': datetime.now().isoformat(),
                'documents_generated': len(generated_docs),
                'document_list': list(generated_docs.keys()),
                'analysis_summary': {
                    'total_files': analysis_results.get('project_info', {}).get('total_files', 0),
                    'main_units': len(analysis_results.get('units_analysis', {})),
                    'has_requirements': 'requirements' in analysis_results,
                    'has_characteristics': 'characteristics' in analysis_results
                }
            }
            
            metadata_path = project_dir / "metadata.json"
            with open(metadata_path, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, indent=2, ensure_ascii=False)
                
            logger.info("‚úÖ Metadados salvos")
            
        except Exception as e:
            logger.error(f"Erro ao salvar metadados: {str(e)}")
    
    def _sanitize_filename(self, filename: str) -> str:
        """Sanitiza nome do arquivo"""
        import re
        # Remove caracteres especiais
        sanitized = re.sub(r'[<>:"/\\|?*]', '_', filename)
        # Remove espa√ßos extras
        sanitized = re.sub(r'\s+', '_', sanitized)
        return sanitized
    
    def regenerate_document_with_feedback(self, doc_key: str, original_content: str, 
                                        feedback: str, analysis_results: Dict[str, Any], 
                                        project_name: str = "Projeto") -> str:
        """
        Regenera documento espec√≠fico com base no feedback
        
        Args:
            doc_key: Chave do documento
            original_content: Conte√∫do original
            feedback: Feedback do usu√°rio
            analysis_results: Dados da an√°lise
            project_name: Nome do projeto
            
        Returns:
            Novo conte√∫do do documento
        """
        try:
            logger.info(f"üîÑ Regenerando documento {doc_key} com feedback")
            
            # Obt√©m prompt espec√≠fico
            doc_config = self.document_types.get(doc_key, {})
            base_prompt = self._get_prompt_for_document(doc_config.get('prompt_type', 'analysis'))
            
            # Cria prompt com feedback
            feedback_prompt = f"""
{base_prompt}

DOCUMENTO ORIGINAL:
{original_content}

FEEDBACK DO USU√ÅRIO:
{feedback}

INSTRU√á√ïES:
- Considere o feedback fornecido
- Mantenha aspectos corretos do documento original
- Corrija problemas identificados no feedback
- Melhore a qualidade e precis√£o
- Mantenha formata√ß√£o markdown
- Foque em aspectos de backend
            """
            
            # Prepara contexto
            context = self._prepare_context(analysis_results, project_name, doc_key)
            
            # Gera novo conte√∫do
            new_content = self._generate_content_with_llm(feedback_prompt, context)
            
            if new_content:
                # Salva vers√£o atualizada
                project_dir = self.docs_dir / self._sanitize_filename(project_name)
                project_dir.mkdir(exist_ok=True)
                
                doc_path = project_dir / doc_config.get('filename', f'{doc_key}.md')
                with open(doc_path, 'w', encoding='utf-8') as f:
                    f.write(new_content)
                
                logger.info(f"‚úÖ Documento {doc_key} regenerado com sucesso")
                return new_content
            else:
                logger.warning(f"‚ö†Ô∏è Falha ao regenerar documento {doc_key}")
                return original_content
                
        except Exception as e:
            logger.error(f"‚ùå Erro ao regenerar documento {doc_key}: {str(e)}")
            return original_content
    
    def get_document_content(self, doc_key_or_path: str, project_name: str = "Projeto") -> str:
        """Obt√©m conte√∫do de um documento espec√≠fico"""
        try:
            # Se for um caminho de arquivo, usa diretamente
            if os.path.isfile(doc_key_or_path):
                with open(doc_key_or_path, 'r', encoding='utf-8') as f:
                    return f.read()
            
            # Caso contr√°rio, trata como doc_key
            doc_config = self.document_types.get(doc_key_or_path, {})
            filename = doc_config.get('filename', f'{doc_key_or_path}.md')
            
            project_dir = self.docs_dir / self._sanitize_filename(project_name)
            doc_path = project_dir / filename
            
            if doc_path.exists():
                with open(doc_path, 'r', encoding='utf-8') as f:
                    return f.read()
            else:
                return f"Documento n√£o encontrado: {doc_key_or_path}"
                
        except Exception as e:
            logger.error(f"Erro ao ler documento {doc_key_or_path}: {str(e)}")
            return f"Erro ao carregar documento: {str(e)}"
    
    def list_generated_documents(self, project_name: str = "Projeto") -> Dict[str, Dict[str, Any]]:
        """Lista documentos gerados para um projeto"""
        try:
            project_dir = self.docs_dir / self._sanitize_filename(project_name)
            
            if not project_dir.exists():
                return {}
            
            documents = {}
            
            for doc_key, doc_config in self.document_types.items():
                filename = doc_config.get('filename', f'{doc_key}.md')
                doc_path = project_dir / filename
                
                if doc_path.exists():
                    stat = doc_path.stat()
                    documents[doc_key] = {
                        'name': doc_config.get('name', doc_key),
                        'path': str(doc_path),
                        'size': stat.st_size,
                        'modified': datetime.fromtimestamp(stat.st_mtime).isoformat()
                    }
            
            return documents
            
        except Exception as e:
            logger.error(f"Erro ao listar documentos: {str(e)}")
            return {}
    
    def get_documentation_summary(self, project_name: str = "Projeto") -> Dict[str, Any]:
        """Obt√©m resumo da documenta√ß√£o gerada"""
        try:
            project_dir = self.docs_dir / self._sanitize_filename(project_name)
            metadata_path = project_dir / "metadata.json"
            
            if metadata_path.exists():
                with open(metadata_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            else:
                return {}
                
        except Exception as e:
            logger.error(f"Erro ao obter resumo: {str(e)}")
            return {}
    
    