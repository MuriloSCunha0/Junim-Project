"""
ConfiguraÃ§Ãµes OTIMIZADAS para DeepSeek-R1 - PERFORMANCE PRIMEIRO
ConfiguraÃ§Ãµes ajustadas para velocidade e menor consumo de recursos
"""

def is_deepseek_r1_model(model_name: str) -> bool:
    """Verifica se Ã© um modelo DeepSeek-R1"""
    return 'deepseek-r1' in model_name.lower()

def get_deepseek_r1_config(model_name: str, performance_mode: str = 'fast') -> dict:
    """
    Retorna configuraÃ§Ãµes otimizadas para DeepSeek-R1 baseadas no modo de performance
    
    Args:
        model_name: Nome do modelo
        performance_mode: 'fast' (padrÃ£o), 'balanced', 'quality'
    """
    
    # ConfiguraÃ§Ãµes BASE OTIMIZADAS para VELOCIDADE
    if performance_mode == 'fast':
        base_config = {
            'temperature': 0.4,        # â†‘ Aumenta para respostas mais rÃ¡pidas
            'top_p': 0.7,             # â†“ Reduz tokens considerados = MAIS RÃPIDO
            'top_k': 25,              # â†“ Reduzido de 50 para 25 = MUITO MAIS RÃPIDO
            'repeat_penalty': 1.05,    # â†“ Reduz processamento de penalidades
            'seed': 42,
            'num_thread': 8,          # â†‘ Usa mais threads disponÃ­veis
            'num_gpu_layers': -1,     # Usa toda GPU disponÃ­vel
        }
        
        if '14b' in model_name.lower():
            base_config.update({
                'num_predict': 1200,   # â†“ DRASTICAMENTE reduzido de 4000
                'num_ctx': 3072,       # â†“ DRASTICAMENTE reduzido de 8192
                'num_batch': 64,       # Lotes menores = menos memÃ³ria
            })
        elif '1.5b' in model_name.lower():
            base_config.update({
                'num_predict': 800,    # â†“ Reduzido de 2000
                'num_ctx': 2048,       # â†“ Reduzido de 4096
                'num_batch': 32,       
            })
        else:
            base_config.update({
                'num_predict': 1000,
                'num_ctx': 2560,
                'num_batch': 48,
            })
    
    elif performance_mode == 'balanced':
        base_config = {
            'temperature': 0.25,       # Meio termo
            'top_p': 0.8,             
            'top_k': 35,              # Meio termo
            'repeat_penalty': 1.08,    
            'seed': 42,
            'num_thread': 6,
            'num_gpu_layers': -1,
        }
        
        if '14b' in model_name.lower():
            base_config.update({
                'num_predict': 2000,   # Meio termo
                'num_ctx': 4096,       # Meio termo
                'num_batch': 96,
            })
        elif '1.5b' in model_name.lower():
            base_config.update({
                'num_predict': 1200,   
                'num_ctx': 3072,       
                'num_batch': 64,
            })
        else:
            base_config.update({
                'num_predict': 1500,
                'num_ctx': 3584,
                'num_batch': 80,
            })
    
    else:  # quality mode
        base_config = {
            'temperature': 0.1,        # Original para qualidade
            'top_p': 0.9,             
            'top_k': 50,              # Original
            'repeat_penalty': 1.1,     
            'seed': 42,
            'num_thread': 4,          # Menos threads para estabilidade
            'num_gpu_layers': -1,
        }
        
        if '14b' in model_name.lower():
            base_config.update({
                'num_predict': 4000,   # Original
                'num_ctx': 8192,       # Original
                'num_batch': 128,
            })
        elif '1.5b' in model_name.lower():
            base_config.update({
                'num_predict': 2000,   # Original
                'num_ctx': 4096,       # Original
                'num_batch': 96,
            })
        else:
            base_config.update({
                'num_predict': 3000,
                'num_ctx': 6144,
                'num_batch': 112,
            })
    
    return base_config

def get_deepseek_r1_system_prompt(task_type: str = 'conversion', performance_mode: str = 'fast') -> str:
    """Retorna prompt de sistema otimizado baseado no modo de performance"""
    
    if performance_mode == 'fast':
        # Prompts ULTRA COMPACTOS para mÃ¡xima velocidade
        compact_prompts = {
            'conversion': "Especialista Delphiâ†’Java Spring Boot. Gere cÃ³digo Java funcional em JSON.",
            'analysis': "Especialista anÃ¡lise Delphi. AnÃ¡lise precisa e estruturada.",
            'documentation': "Especialista tÃ©cnico. Doc clara e estruturada.",
            'mermaid_diagram': "Especialista arquitetura. Gere diagramas Mermaid vÃ¡lidos.",
            'testing': "Especialista testes. Gere testes JUnit funcionais."
        }
        return compact_prompts.get(task_type, "Especialista modernizaÃ§Ã£o Delphiâ†’Java.")
    
    elif performance_mode == 'balanced':
        # Prompts MODERADOS
        base_prompt = "Especialista em migraÃ§Ã£o Delphi para Java Spring Boot."
        task_prompts = {
            'conversion': f"{base_prompt} Gere cÃ³digo Java funcional em JSON com boa qualidade.",
            'analysis': f"{base_prompt} FaÃ§a anÃ¡lises detalhadas de cÃ³digo Delphi.",
            'documentation': f"{base_prompt} Gere documentaÃ§Ã£o tÃ©cnica estruturada."
        }
        return task_prompts.get(task_type, base_prompt)
    
    else:  # quality mode - mantÃ©m original
        base_prompt = "VocÃª Ã© um especialista em migraÃ§Ã£o de sistemas Delphi para Java Spring Boot."
        task_prompts = {
            'conversion': f"{base_prompt} Use seu conhecimento avanÃ§ado para gerar cÃ³digo Java funcional de alta qualidade no formato JSON com as chaves 'files' contendo uma lista de arquivos. Seja preciso e detalhado.",
            'analysis': f"{base_prompt} Use seu conhecimento para fazer anÃ¡lises detalhadas e precisas de cÃ³digo Delphi.",
            'documentation': f"{base_prompt} Use seu conhecimento para gerar documentaÃ§Ã£o tÃ©cnica completa e precisa."
        }
        return task_prompts.get(task_type, base_prompt)

def combine_prompts_with_deepseek(base_prompt: str, task_type: str = 'conversion', performance_mode: str = 'fast') -> str:
    """
    Combina prompts otimizado para diferentes modos de performance
    
    Args:
        base_prompt: Prompt base do sistema
        task_type: Tipo de tarefa
        performance_mode: 'fast', 'balanced', 'quality'
    """
    if not base_prompt or not base_prompt.strip():
        return get_deepseek_r1_system_prompt(task_type, performance_mode)
    
    if performance_mode == 'fast':
        # ULTRA COMPACTO - MÃ¡xima velocidade
        return f"""TAREFA: {task_type.upper()}
{get_deepseek_r1_system_prompt(task_type, 'fast')}

ENTRADA: {base_prompt[:300]}...

SAÃDA: Resposta direta conforme solicitado."""
    
    elif performance_mode == 'balanced':
        # MODERADO - EquilÃ­brio velocidade/qualidade
        return f"""CONTEXTO: {get_deepseek_r1_system_prompt(task_type, 'balanced')}

TAREFA: {task_type}
{base_prompt[:800]}...

INSTRUÃ‡Ã•ES:
- Resposta estruturada
- Foque no essencial
- Qualidade tÃ©cnica

FORMATO: Conforme especificado."""
    
    else:  # quality mode - mantÃ©m original detalhado
        return f"""CONTEXTO DE SISTEMA:
{get_deepseek_r1_system_prompt(task_type, 'quality')}

PROMPT ESPECIALIZADO:
{base_prompt}

INSTRUÃ‡Ã•ES ESPECÃFICAS PARA DEEPSEEK-R1:
- Use raciocÃ­nio passo-a-passo
- Seja preciso e detalhado
- ForneÃ§a respostas estruturadas
- Mantenha consistÃªncia tÃ©cnica
- Foque em qualidade de cÃ³digo

FORMATO DE RESPOSTA ESPERADO:
- Para cÃ³digo: JSON estruturado conforme especificado
- Para anÃ¡lise: Markdown estruturado com seÃ§Ãµes claras
- Para documentaÃ§Ã£o: Formato tÃ©cnico detalhado
"""

def get_deepseek_enhanced_options(model_name: str, task_type: str, performance_mode: str = 'fast') -> dict:
    """
    Retorna opÃ§Ãµes aprimoradas especÃ­ficas para DeepSeek-R1 baseadas no modo de performance
    """
    base_options = get_deepseek_r1_config(model_name, performance_mode)
    
    # Ajustes especÃ­ficos por tipo de tarefa e modo de performance
    if performance_mode == 'fast':
        # ConfiguraÃ§Ãµes ULTRA RÃPIDAS por tipo de tarefa
        task_adjustments = {
            'conversion': {
                'temperature': 0.5,    # Alto para velocidade
                'top_p': 0.6,         # Baixo para rapidez
                'top_k': 20,          # Muito baixo
            },
            'analysis': {
                'temperature': 0.4,
                'top_p': 0.65,
                'top_k': 25,
            },
            'documentation': {
                'temperature': 0.45,
                'top_p': 0.7,
                'top_k': 30,
            },
            'mermaid_diagram': {
                'temperature': 0.3,
                'top_p': 0.7,
                'top_k': 25,
            },
            'testing': {
                'temperature': 0.35,
                'top_p': 0.65,
                'top_k': 25,
            }
        }
    elif performance_mode == 'balanced':
        # ConfiguraÃ§Ãµes EQUILIBRADAS
        task_adjustments = {
            'conversion': {
                'temperature': 0.2,
                'top_p': 0.8,
                'top_k': 35,
            },
            'analysis': {
                'temperature': 0.25,
                'top_p': 0.85,
                'top_k': 40,
            },
            'documentation': {
                'temperature': 0.3,
                'top_p': 0.9,
                'top_k': 45,
            },
            'mermaid_diagram': {
                'temperature': 0.15,
                'top_p': 0.8,
                'top_k': 35,
            },
            'testing': {
                'temperature': 0.2,
                'top_p': 0.8,
                'top_k': 35,
            }
        }
    else:  # quality mode - configuraÃ§Ãµes originais
        task_adjustments = {
            'conversion': {
                'temperature': 0.05,  # Mais determinÃ­stico para cÃ³digo
                'top_p': 0.8,
                'top_k': 50,
            },
            'analysis': {
                'temperature': 0.1,
                'top_p': 0.9,
                'top_k': 50,
            },
            'documentation': {
                'temperature': 0.15,
                'top_p': 0.95,
                'top_k': 50,
            },
            'mermaid_diagram': {
                'temperature': 0.05,
                'top_p': 0.85,
                'top_k': 45,
            },
            'testing': {
                'temperature': 0.1,
                'top_p': 0.85,
                'top_k': 45,
            }
        }
    
    if task_type in task_adjustments:
        base_options.update(task_adjustments[task_type])
    
    return base_options

def get_performance_info() -> dict:
    """Retorna informaÃ§Ãµes sobre os modos de performance disponÃ­veis"""
    return {
        'fast': {
            'description': 'ğŸš€ VELOCIDADE MÃXIMA - Ideal para experimentos rÃ¡pidos',
            'speed': 'âš¡ Muito RÃ¡pido',
            'memory': 'ğŸ’¾ Baixo uso',
            'quality': 'ğŸ“Š AceitÃ¡vel',
            'use_case': 'Testes rÃ¡pidos, iteraÃ§Ãµes de desenvolvimento, experimentos',
            'savings': 'CPU: ~60% menos | MemÃ³ria: ~70% menos | Tempo: ~3x mais rÃ¡pido'
        },
        'balanced': {
            'description': 'âš–ï¸ EQUILIBRADO - Bom compromisso velocidade/qualidade',
            'speed': 'ğŸƒ RÃ¡pido',
            'memory': 'ğŸ’¾ Moderado',
            'quality': 'ğŸ“Š Boa',
            'use_case': 'Desenvolvimento normal, anÃ¡lises rotineiras',
            'savings': 'CPU: ~30% menos | MemÃ³ria: ~40% menos | Tempo: ~1.5x mais rÃ¡pido'
        },
        'quality': {
            'description': 'ğŸ¯ QUALIDADE MÃXIMA - Para resultados finais',
            'speed': 'ğŸ¢ Mais lento',
            'memory': 'ğŸ’¾ Alto uso',
            'quality': 'ğŸ“Š MÃ¡xima',
            'use_case': 'ProduÃ§Ã£o, anÃ¡lises finais, cÃ³digo crÃ­tico',
            'savings': 'ConfiguraÃ§Ãµes originais para mÃ¡xima qualidade'
        }
    }
